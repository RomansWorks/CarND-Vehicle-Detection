{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SETTING_RETRAIN_CLASSIFIER = False         # Change this to retrain the classifier\n",
    "SETTING_SAVE_RETRAINED_CLASSIFIER = True   # Change this to save the retrained classifier (if retraining)\n",
    "SETTING_LOAD_TRAINED_CLASSIFIER = True     # Change this in case SETTING_SAVE_RETRAINED_CLASSIFIER and you want to use the freshly trained classifier without overwriting the one on disc\n",
    "SETTING_TEST_CLASSIFIER_ON_TEST_IMAGES = False  # Change this to show how the classifier works on test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Note: Uses OpenCV 3.2 with Contrib (pip install opencv-contrib-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rbaron/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SKLearn\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn import svm\n",
    "from skimage.feature import hog\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# MatPlotLib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# The rest\n",
    "import numpy as np\n",
    "from scipy.ndimage.measurements import label\n",
    "import cv2\n",
    "from glob import glob\n",
    "import random\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define Feature Extraction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, color_space='LUV'):\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: \n",
    "        feature_image = np.copy(img)\n",
    "    return feature_image   \n",
    "\n",
    "def get_hog_features(img, \n",
    "                     orient,\n",
    "                     pix_per_cell, \n",
    "                     cell_per_block,\n",
    "                     vis=False, \n",
    "                     feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size, interpolation=cv2.INTER_LINEAR).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size, interpolation=cv2.INTER_LINEAR).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size, interpolation=cv2.INTER_LINEAR).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):    #\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (64, 64)\n",
    "\n",
    "color_space = 'LUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 12  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 1 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (48, 48) # Spatial binning dimensions\n",
    "hist_bins = 64    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_features(img, color_space=color_space, spatial_size=spatial_size, hist_bins=hist_bins, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                        spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat):   \n",
    "    img_resize = cv2.resize(img, spatial_size, interpolation=cv2.INTER_LINEAR)\n",
    "    img_resize = (np.sqrt(img_resize.astype(np.float32)/255)*255).astype(np.uint8)    \n",
    "    file_features = []   \n",
    "    feature_image = convert_color(img_resize, color_space=color_space)\n",
    "    file_features.append(feature_image.ravel())\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        file_features.append(spatial_features)\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        file_features.append(hist_features)\n",
    "    if hog_feat == True:\n",
    "    # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block)\n",
    "        # Append the new feature vector to the features list\n",
    "    file_features.append(hog_features)   \n",
    "    #  print(len(file_features), len(spatial_features), len(hist_features), len(hog_features)) \n",
    "    return np.concatenate(file_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load training data for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if SETTING_RETRAIN_CLASSIFIER == True:\n",
    "    # total_imgs = 0\n",
    "    SAMPLES_TO_USE = 8000\n",
    "\n",
    "    vehicle_fnames = glob('dataset/vehicles/*/*.png')\n",
    "    non_vehicle_fnames = glob('dataset/non-vehicles/*/*.png')\n",
    "\n",
    "    vehicle_fnames = random.sample(vehicle_fnames, SAMPLES_TO_USE)\n",
    "    non_vehicle_fnames = random.sample(non_vehicle_fnames, SAMPLES_TO_USE)\n",
    "\n",
    "    print(\"Sampling complete, loading images\")\n",
    "\n",
    "    car_images = [mpimg.imread(fname) for fname in vehicle_fnames]\n",
    "    non_car_images = [mpimg.imread(fname) for fname in non_vehicle_fnames]\n",
    "\n",
    "    # Normalize\n",
    "    car_images = [(image.astype(np.float32)/np.max(image)*255).astype(np.uint8) for image in car_images]\n",
    "    non_car_images = [(image.astype(np.float32)/np.max(image)*255).astype(np.uint8) for image in non_car_images]\n",
    "\n",
    "    print(\"Loading complete, extracting features\")\n",
    "\n",
    "    car_features = [extract_features(image) for image in car_images]\n",
    "    non_car_features = [extract_features(image) for image in non_car_images]\n",
    "\n",
    "    print(\"Extracting complete\")\n",
    "\n",
    "    X_cars = np.vstack(car_features)\n",
    "    y_cars = np.ones(X_cars.shape[0], dtype=np.uint8)\n",
    "    X_non_cars = np.vstack(non_car_features)\n",
    "    y_non_cars = np.zeros(X_non_cars.shape[0], dtype=np.uint8)\n",
    "\n",
    "    X = np.vstack((X_cars, X_non_cars))\n",
    "    y = np.concatenate((y_cars, y_non_cars))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Normalize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if SETTING_RETRAIN_CLASSIFIER == True:\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    print('{} cars labeled & {} non-cars labeled'.format(len(X_cars), len(X_non_cars)))\n",
    "    del X_cars\n",
    "    del X_non_cars\n",
    "\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# After trying an (nearly) infite number of kernels via grid search... I  settle on the best performing one\n",
    "SEARCH_C_VALUES=[0.0001]\n",
    "SEARCH_KERNEL_VALUES=['linear'] \n",
    "SEARCH_GAMMA_VALUES=[0.00001]\n",
    "parameters = {'kernel': SEARCH_KERNEL_VALUES, 'C': SEARCH_C_VALUES, 'gamma': SEARCH_GAMMA_VALUES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Grid search (commented out because we have a good parameter combination now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def optimize_param(parameters):\n",
    "#     svc = GridSearchCV(svm.SVC(), parameters)\n",
    "#     # Check the training time for the SVC\n",
    "#     t=time.time()\n",
    "#     svc.fit(X_train, y_train)\n",
    "#     t2 = time.time()\n",
    "#     print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "#     optimal_params = svc.best_params_\n",
    "#     print(\"Optimal parameters found: \", optimal_params, \"\\n\")\n",
    "#     # Check the score of the SVC\n",
    "#     test_score = round(svc.score(X_test, y_test), 4)\n",
    "#     print('Test Accuracy of SVC = ', test_score)\n",
    "#     # Check the prediction time for a single sample\n",
    "#     t=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if SETTING_RETRAIN_CLASSIFIER == True:\n",
    "    print('Using:',orient,'orientations',pix_per_cell,\n",
    "        'pixels per cell and', cell_per_block,'cells per block')\n",
    "    print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "    svca = LinearSVC(C=0.0001, dual=False, max_iter=5)\n",
    "\n",
    "\n",
    "    Batch_size = len(X_train)//5\n",
    "    print('training on {} samples, {} batches, each batch {} samples'.format(len(X_train), len(X_train)//Batch_size, Batch_size))\n",
    "\n",
    "    for batch in range(0,len(X_train)//Batch_size):\n",
    "    # for batch in range(0,2):\n",
    "        t=time.time()\n",
    "        svca.fit(X_train[batch*Batch_size:(batch+1)*Batch_size], y_train[batch*Batch_size:(batch+1)*Batch_size])\n",
    "        t2 = time.time()\n",
    "        print('batch:', batch+1,'-', round(t2-t, 2), 'Seconds to train SVC...')\n",
    "\n",
    "        # Check the score of the SVC\n",
    "        test_score = round(svca.score(X_test, y_test), 4)\n",
    "        print('Test Accuracy of SVC = ', test_score)\n",
    "        # Check the prediction time for a single sample\n",
    "        t=time.time()\n",
    "    print ('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Print statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if SETTING_RETRAIN_CLASSIFIER == True:\n",
    "    predict = svca.predict(X_test)\n",
    "\n",
    "    def print_stats(labels, predict):\n",
    "        print(labels[:20])\n",
    "        print(predict[:20])\n",
    "        cm = confusion_matrix(labels, predict)\n",
    "        tot = cm.sum()\n",
    "        TN = cm[0][0]/tot\n",
    "        FP = cm[0][1]/tot\n",
    "        FN = cm[1][0]/tot\n",
    "        TP = cm[1][1]/tot\n",
    "        print(\"%s %.2f%% %s %.2f%% %s %.2f%% %s %.2f%%\\n\" % ('TP:',TP, 'FP:',FP, 'TN:',TN, 'FN:',FN))   \n",
    "        print(classification_report(labels, predict))\n",
    "\n",
    "    print_stats(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Save the classifier if we're happy with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "CLASSIFIER_SAVE_PATH = 'intermediates/car_classifier.pkl'\n",
    "SCALER_SAVE_PATH = 'intermediates/car_scaler.pkl'\n",
    "\n",
    "if SETTING_SAVE_RETRAINED_CLASSIFIER == True and SETTING_RETRAIN_CLASSIFIER == True:\n",
    "    joblib.dump(svca, CLASSIFIER_SAVE_PATH)\n",
    "    joblib.dump(X_scaler, SCALER_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load the saved classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier loaded successfully:\n",
      "LinearSVC(C=0.0001, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=5,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Scaler loaded successfully:\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "SETTING_LOAD_TRAINED_CLASSIFIER = True\n",
    "CLASSIFIER_LOAD_PATH = 'intermediates/car_classifier.pkl'\n",
    "SCALER_LOAD_PATH = 'intermediates/car_scaler.pkl'\n",
    "if SETTING_LOAD_TRAINED_CLASSIFIER == True:\n",
    "    svc = None\n",
    "    svc = joblib.load(CLASSIFIER_LOAD_PATH)\n",
    "    if svc != None:\n",
    "        print('Classifier loaded successfully:')\n",
    "        print(svc)\n",
    "    X_scaler = joblib.load(SCALER_LOAD_PATH)\n",
    "    if X_scaler != None:\n",
    "        print('Scaler loaded successfully:')\n",
    "        print(X_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define the window search and conversion to bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "WINDOW_SEARCH_RANGES = [\n",
    "#      {'window_size': (256,256), 'x_start_stop': [None, None], 'y_start_stop': [360, 740], 'xy_overlap':(0.8, 0.8)},\n",
    "     {'window_size': (192,192), 'x_start_stop': [None, None], 'y_start_stop': [360, 740], 'xy_overlap':(0.8, 0.8)},\n",
    "     {'window_size': (128,128), 'x_start_stop': [50, 1300], 'y_start_stop': [360, 600], 'xy_overlap':(0.8, 0.8)},\n",
    "     {'window_size': (64,64), 'x_start_stop': [200, 1200], 'y_start_stop': [360, 500], 'xy_overlap':(0.85, 0.85)},\n",
    "]\n",
    "\n",
    "def search_windows(img, windows, clf, scaler, color_space=color_space, spatial_size=spatial_size, hist_bins=hist_bins, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                        spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "#         print(window)\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], IMG_SHAPE)\n",
    "        \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = extract_features(test_img, color_space=color_space, spatial_size=spatial_size, hist_bins=hist_bins, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                        spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        \n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        \n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows\n",
    "\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=4):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "def heatmap_from_positives(image, positive_windows):\n",
    "    heatmap = np.zeros(image.shape[0:2])\n",
    "    for window in positive_windows:\n",
    "        heatmap[window[0][1]:window[1][1], window[0][0]:window[1][0]] += 1\n",
    "    return heatmap\n",
    "\n",
    "def get_all_windows(image):\n",
    "    all_windows = []\n",
    "    for search_range in WINDOW_SEARCH_RANGES:\n",
    "        windows = slide_window(image, \n",
    "                               xy_window=search_range['window_size'],\n",
    "                               x_start_stop=search_range['x_start_stop'], \n",
    "                               y_start_stop=search_range['y_start_stop'], \n",
    "                               xy_overlap=search_range['xy_overlap'])\n",
    "        all_windows.extend(windows)\n",
    "    return all_windows\n",
    "\n",
    "# def get_var_windows(window_sizes):\n",
    "#     ret_windows = []\n",
    "#     for size in window_sizes:\n",
    "#         ret_windows.extend(slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "#                     xy_window=(size, size), xy_overlap=search_windows_overlap))\n",
    "#     return ret_windows\n",
    "\n",
    "def get_labeled_bboxes(labels):\n",
    "    bboxes = []\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        bboxes.append(bbox)\n",
    "    return bboxes\n",
    "\n",
    "def get_bbox_center(bbox):\n",
    "    x = (bbox[1][0] - bbox[0][0])/2 + bbox[0][0]\n",
    "    y = (bbox[1][1] - bbox[0][1])/2 + bbox[0][1]\n",
    "    return (int(x),int(y))\n",
    "\n",
    "# test_bb = ((100, 500), (300, 700))\n",
    "# test = get_bbox_center(test_bb)\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Try classifier on provided test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DETECTION_THRESHOLD = 4\n",
    "\n",
    "if SETTING_TEST_CLASSIFIER_ON_TEST_IMAGES:\n",
    "    files = glob('test_images/test*.jpg')\n",
    "    for file in files:\n",
    "        image = mpimg.imread(file)\n",
    "        draw_image = np.copy(image)\n",
    "\n",
    "        windows = get_all_windows(image)\n",
    "        \n",
    "        hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block, \n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "\n",
    "        all_windows_img = draw_boxes(draw_image, windows)\n",
    "        positive_labeled_windows = draw_boxes(draw_image, hot_windows)\n",
    "\n",
    "        heatmap = heatmap_from_positives(image, hot_windows)\n",
    "        heatmap_orig = np.copy(heatmap)\n",
    "        # Threshold\n",
    "        heatmap[heatmap <= DETECTION_THRESHOLD] = 0\n",
    "        # Label separate detections\n",
    "        labels = label(heatmap)\n",
    "        # Calculate bounding boxes for labels\n",
    "        detected_bboxes = get_labeled_bboxes(labels)\n",
    "        # Draw bounding boxes on image\n",
    "        if detected_bboxes is not None:\n",
    "            img_with_bboxes = draw_boxes(image, detected_bboxes)\n",
    "        else: \n",
    "            img_with_bboxes = image\n",
    "\n",
    "        # Plot\n",
    "        f, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(24, 10))\n",
    "        f.tight_layout()\n",
    "        ax1.set_title('Scanned Windows', fontsize=30)\n",
    "        ax1.imshow(all_windows_img)\n",
    "        ax2.set_title('Positive Scans', fontsize=30)\n",
    "        ax2.imshow(positive_labeled_windows)\n",
    "        ax3.set_title('Heatmap before threshold', fontsize=30)\n",
    "        ax3.imshow(heatmap_orig, cmap='gray')\n",
    "        ax4.set_title('Heatmap after threshold', fontsize=30)\n",
    "        ax4.imshow(heatmap, cmap='hot')\n",
    "        ax5.set_title('Labels', fontsize=30)\n",
    "        ax5.imshow(labels[0], cmap='gray')\n",
    "        ax6.set_title('Final Detections', fontsize=30)\n",
    "        ax6.imshow(img_with_bboxes)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.1, hspace=0.2)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define and test some bounding box manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((90, 520), (190, 720))\n",
      "None\n",
      "Step size for horiz 9\n",
      "Step size for vert 19\n",
      "[((100, 500), (200, 700)), ((91, 500), (191, 700)), ((109, 500), (209, 700)), ((100, 481), (200, 681)), ((100, 519), (200, 719)), ((91, 481), (191, 681)), ((109, 481), (209, 681)), ((91, 519), (191, 719)), ((109, 519), (209, 719))]\n"
     ]
    }
   ],
   "source": [
    "# Shift a bounding box by a horizontal and vertical shift but retain its size\n",
    "# Drops the window (returns None) if any of its coordinates cross the keep_bbox\n",
    "def shift_bbox(bbox, horizontal_shift, vertical_shift, keep_bbox):\n",
    "    p1 = bbox[0]\n",
    "    p1_x = p1[0]\n",
    "    p1_y = p1[1]\n",
    "    p2 = bbox[1]\n",
    "    p2_x = p2[0]\n",
    "    p2_y = p2[1] \n",
    "    \n",
    "    new_p1_x = p1_x+horizontal_shift\n",
    "    new_p1_y = p1_y+vertical_shift\n",
    "    new_p2_x = p2_x+horizontal_shift\n",
    "    new_p2_y = p2_y+vertical_shift\n",
    "    shifted = ((new_p1_x, new_p1_y),(new_p2_x, new_p2_y)) \n",
    "    if new_p1_x < keep_bbox[0][0] or new_p1_y < keep_bbox[0][1] or new_p2_x > keep_bbox[1][0] or new_p2_y > keep_bbox[1][1]:\n",
    "        return None\n",
    "    return shifted\n",
    "\n",
    "# Create nearby boxes around a bbox. Used for incremental search\n",
    "def bbox_to_nearby(bbox, steps_per_direction, step_overlap_horiz, step_overlap_vert, scale, keep_bbox):\n",
    "    p1 = bbox[0]\n",
    "    p1_x = p1[0]\n",
    "    p1_y = p1[1]\n",
    "    p2 = bbox[1]\n",
    "    p2_x = p2[0]\n",
    "    p2_y = p2[1]\n",
    "    width = p2_x-p1_x\n",
    "    height = p2_y-p1_y\n",
    "    horizontal_step_size = int(width * (1-step_overlap_horiz))\n",
    "    vertical_step_size = int(height * (1-step_overlap_vert))\n",
    "    print(\"Step size for horiz\", horizontal_step_size)\n",
    "    print(\"Step size for vert\", vertical_step_size)\n",
    "    \n",
    "    windows = []\n",
    "    windows.append(bbox)\n",
    "    # Create windows per step in each direction\n",
    "    for step in range(1, steps_per_direction+1):\n",
    "        horiz_shift = horizontal_step_size*step\n",
    "        vert_shift = vertical_step_size*step\n",
    "        \n",
    "        left_win = shift_bbox(bbox, -horiz_shift, 0, keep_bbox)\n",
    "        right_win = shift_bbox(bbox, +horiz_shift, 0, keep_bbox)\n",
    "        top_win = shift_bbox(bbox, 0, -vert_shift, keep_bbox)     \n",
    "        bottom_win = shift_bbox(bbox, 0, +vert_shift, keep_bbox)\n",
    "        windows.extend([left_win, right_win, top_win, bottom_win])\n",
    "\n",
    "        top_left_win = shift_bbox(bbox, -horiz_shift, -vert_shift, keep_bbox)\n",
    "        top_right_win = shift_bbox(bbox, +horiz_shift, -vert_shift, keep_bbox)\n",
    "        bottom_left_win = shift_bbox(bbox, -horiz_shift, +vert_shift, keep_bbox)     \n",
    "        bottom_right_win = shift_bbox(bbox, +horiz_shift, +vert_shift, keep_bbox) \n",
    "        windows.extend([top_left_win, top_right_win, bottom_left_win, bottom_right_win])\n",
    "\n",
    "    # Filter out None windows (windows dropped due to boundary)\n",
    "    windows = [window for window in windows if window is not None]\n",
    "    return windows\n",
    "\n",
    "keep_bbox = ((0,0),(1280, 720))\n",
    "bbox1 = ((100,500),(200,700))\n",
    "res = shift_bbox(bbox1, -10, 20, keep_bbox)\n",
    "print(res) # should print ((90, 520), (190, 720))\n",
    "res = shift_bbox(bbox1, 10, 30, keep_bbox)\n",
    "print(res) # should print \"None\"\n",
    "ress = bbox_to_nearby(bbox1, 1, 0.9, 0.9, 1, keep_bbox)\n",
    "print(ress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Use the classifier on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch frame found\n"
     ]
    }
   ],
   "source": [
    "def detect_cars_in_frame(image, windows):\n",
    "    hot_windows = search_windows(image, \n",
    "                                 windows, \n",
    "                                 svc, \n",
    "                                 X_scaler, \n",
    "                                 color_space=color_space, \n",
    "                                 spatial_size=spatial_size, \n",
    "                                 hist_bins=hist_bins, \n",
    "                                 orient=orient, \n",
    "                                 pix_per_cell=pix_per_cell, \n",
    "                                 cell_per_block=cell_per_block, \n",
    "                                 hog_channel=hog_channel, \n",
    "                                 spatial_feat=spatial_feat, \n",
    "                                 hist_feat=hist_feat,\n",
    "                                 hog_feat=hog_feat)                       \n",
    "\n",
    "    heatmap = heatmap_from_positives(image, hot_windows)\n",
    "    # Threshold\n",
    "    heatmap[heatmap <= DETECTION_THRESHOLD] = 0\n",
    "    # Label separate detections\n",
    "    labels = label(heatmap)\n",
    "    # Calculate bounding boxes for labels\n",
    "    detected_bboxes = get_labeled_bboxes(labels)\n",
    "    \n",
    "    return detected_bboxes\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "video = cv2.VideoCapture('test_video.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_out = cv2.VideoWriter('test_video_processed.avi', fourcc, fps=20.0, frameSize=(1280,720), isColor=True)\n",
    "\n",
    "FRAMES_BATCH_SIZE = 20  \n",
    "NEARBY_WINDOW_OVERLAP_HORIZ = 0.95\n",
    "NEARBY_WINDOW_OVERLAP_VERT = 0.98\n",
    "NEARBY_WINDOW_STEPS_PER_DIRECTION = 2\n",
    "NEARBY_WINDOW_SCALEDOWN = 0.98\n",
    "\n",
    "has_reached_end = False\n",
    "previous_batch_detections = None\n",
    "full_scan_windows = None\n",
    "frame_idx = 0\n",
    "trackers = []\n",
    "while(video.isOpened() and not has_reached_end):\n",
    "    time_op_start = time.time()\n",
    "\n",
    "    # Read a frame, make sure we're not at the end\n",
    "    ret, frame = video.read()\n",
    "    if ret == False:\n",
    "        has_reached_end = True\n",
    "        break\n",
    "       \n",
    "    # Get the full scan windows for the first time if needed\n",
    "    if full_scan_windows is None:\n",
    "        full_scan_windows = get_all_windows(frame)\n",
    "    \n",
    "    # For FRAMES_BATCH_SIZE frames, do full detection. \n",
    "    # Otherwise, just continue detecting using the trackers\n",
    "    frame_detections = []\n",
    "    if frame_idx % FRAMES_BATCH_SIZE == 0:\n",
    "        print(\"Batch frame found\")\n",
    "        frame_detections = detect_cars_in_frame(\n",
    "            frame,\n",
    "            full_scan_windows\n",
    "        )\n",
    "        print(\"Creating trackers for detections\")\n",
    "\n",
    "        for detection in frame_detections:\n",
    "            print(\"Creating Tracker\")\n",
    "            tracker = cv2.Tracker_create(\"KCF\")\n",
    "            tracker_bbox = (\n",
    "                detection[0][0], \n",
    "                detection[0][1], \n",
    "                detection[1][0] - detection[0][0],\n",
    "                detection[1][1] - detection[0][1]\n",
    "            )\n",
    "            print(\"Initializing tracker with bbox: \", tracker_bbox)\n",
    "            tracker.init(frame, tracker_bbox)\n",
    "            trackers.append(tracker)\n",
    "    else:\n",
    "        print(\"Incremental frame found\")\n",
    "\n",
    "        for idx, tracker in trackers:\n",
    "            ok, bbox = tracker.update(frame)\n",
    "            print(\"Tracker {} new bbox: {}\".format(ok, bbox))\n",
    "            if ok:\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                frame_detections.append((p1[0], p1[1], p2[0], p2[1]))\n",
    "            else:\n",
    "                print(\"Tracker lost\")\n",
    "    \n",
    "\n",
    "    out_frame = draw_boxes(frame, frame_detections)\n",
    "    video_out.write(out_frame)\n",
    "    \n",
    "#     # Get a batch of frames of size FRAMES_BATCH_SIZE\n",
    "#     frames_batch = []\n",
    "#     for i in range(0, FRAMES_BATCH_SIZE):    \n",
    "#         ret, frame = video.read()\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             has_reached_end = True\n",
    "#             break\n",
    "#         if ret==True:\n",
    "#             frames_batch.append(frame)\n",
    "#         else:\n",
    "#             has_reached_end = True\n",
    "#             break\n",
    "        \n",
    "#     if len(frames_batch) == 0:\n",
    "#         break\n",
    "        \n",
    "#     if full_scan_windows is None:\n",
    "#         full_scan_windows = get_all_windows(frames_batch[0])\n",
    "        \n",
    "#     detections_per_frame = {}\n",
    "#     first_frame_detections = detect_cars_in_frame(\n",
    "#         frames_batch[0],\n",
    "#         full_scan_windows\n",
    "#     )\n",
    "#     detections_per_frame[0] = first_frame_detections\n",
    "#     for i in range(1,len(frames_batch)):\n",
    "#         prev_frame_detections = detections_per_frame[i-1]\n",
    "#         frame_search_windows = []\n",
    "#         for detection in prev_frame_detections:\n",
    "#             nearby_windows = bbox_to_nearby(detection, \n",
    "#                                             NEARBY_WINDOW_STEPS_PER_DIRECTION, \n",
    "#                                             NEARBY_WINDOW_OVERLAP_HORIZ,\n",
    "#                                             NEARBY_WINDOW_OVERLAP_VERT,\n",
    "#                                             NEARBY_WINDOW_SCALEDOWN, \n",
    "#                                             ((0,0), (1280, 720))\n",
    "#                                            )\n",
    "#             frame_search_windows.extend(nearby_windows)\n",
    "            \n",
    "#         frame_detections = detect_cars_in_frame(\n",
    "#             frames_batch[i], \n",
    "#             frame_search_windows\n",
    "#         )   \n",
    "#         detections_per_frame[i] = frame_detections\n",
    "#         print(frame_detections)\n",
    "#         frames_batch[i] = draw_boxes(frames_batch[i], frame_detections)\n",
    "    \n",
    "#     # Write resulting frames\n",
    "#     for out_frame in frames_batch:\n",
    "#         video_out.write(out_frame)\n",
    "    \n",
    "    # Original pipeline time per frame was 9 seconds on my laptop.\n",
    "    # To build a real-time pipeline we need 2 orders of magnitute improvement (<16ms for 60fps)\n",
    "    time_op_end = time.time()\n",
    "    print('Time per frame: {}', (time_op_end - time_op_start))\n",
    "\n",
    "#     print('Time per frame: {}', (time_op_end - time_op_start)/len(frames_batch))\n",
    "  \n",
    "\n",
    "print(\"Releasing everything\")\n",
    "video.release()\n",
    "video_out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # import IPython.display as disp\n",
    "# import base64\n",
    "# # disp.Video()\n",
    "# def video(fname, mimetype):\n",
    "#     from IPython.display import HTML\n",
    "#     video_not_encoded = open(fname, \"rb\").read()\n",
    "#     video_encoded = base64.b64encode(video_not_encoded)\n",
    "#     video_tag = '<video controls alt=\"test\" src=\"data:video/{0};base64,{1}\">'.format(mimetype, video_encoded.decode())\n",
    "#     return HTML(data=video_tag)\n",
    "\n",
    "# video(\"test_video_processed.avi\", \"avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Trackers to try: KCF, MEDIANFLOW, GOTURN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
